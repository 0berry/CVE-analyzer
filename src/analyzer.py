#!/usr/bin/env python
# coding: utf8

import plac
import random
from pathlib import Path
import spacy
from spacy.util import minibatch, compounding


# new entity label
LABELS = [
    "FUNCTION",
    "VERSION",
    "SOURCECODE",
    "DRIVER",
    "STRUCT"
]

# training data
TRAIN_DATA = [
    ["Linux Kernel version 3.18 to 4.16 incorrectly handles an SG_IO ioctl on /dev/sg0 with dxfer_direction=SG_DXFER_FROM_DEV and an empty 6-byte cmdp. This may lead to copying up to 1000 kernel heap pages to the userspace. This has been fixed upstream in https://github.com/torvalds/linux/commit/a45b599ad808c3c982fdcdc12b0b8611c2f92824 already. The problem has limited scope, as users don't usually have permissions to access SCSI devices. On the other hand, e.g. the Nero user manual suggests doing `chmod o+r+w /dev/sg*` to make the devices accessible. NOTE: third parties dispute the relevance of this report, noting that the requirement for an attacker to have both the CAP_SYS_ADMIN and CAP_SYS_RAWIO capabilities makes it \"virtually impossible to exploit.\"", {
        "entities": [
            [57, 62, "FUNCTION"],
            [86, 101, "FUNCTION"],
            [102, 119, "FUNCTION"],
            [670, 683, "FUNCTION"],
            [688, 701, "FUNCTION"],
            [21, 25, "VERSION"],
            [29, 33, "VERSION"],
            [72, 80, "DRIVER"],
            [265, 331, "DRIVER"],
            [509, 516, "DRIVER"]
        ]
    }],
    ["The Linux Kernel versions 4.14, 4.15, and 4.16 has a null pointer dereference which can result in an out of memory (OOM) killing of large mlocked processes. The issue arises from an oom killed process's final thread calling exit_mmap(), which calls munlock_vma_pages_all() for mlocked vmas.This can happen synchronously with the oom reaper's unmap_page_range() since the vma's VM_LOCKED bit is cleared before munlocking (to determine if any other vmas share the memory and are mlocked).", {
        "entities": [
            [224, 233, "FUNCTION"],
            [249, 270, "FUNCTION"],
            [342, 358, "FUNCTION"],
            [377, 386, "FUNCTION"],
            [26, 30, "VERSION"],
            [32, 36, "VERSION"],
            [42, 46, "VERSION"]
        ]
    }],
    ["The Linux Kernel version 3.18 contains a dangerous feature vulnerability in modify_user_hw_breakpoint() that can result in crash and possibly memory corruption. This attack appear to be exploitable via local code execution and the ability to use ptrace. This vulnerability appears to have been fixed in git commit f67b15037a7a50c57f72e69a6d59941ad90a0f0f.", {
        "entities": [
            [76, 101, "FUNCTION"],
            [25, 29, "VERSION"]
        ]
    }],
    ["Linux kernel version after commit bdcf0a423ea1 - 4.15-rc4+, 4.14.8+, 4.9.76+, 4.4.111+ contains a Incorrect Access Control vulnerability in NFS server (nfsd) that can result in remote users reading or writing files they should not be able to via NFS. This attack appear to be exploitable via NFS server must export a filesystem with the \"rootsquash\" options enabled. This vulnerability appears to have been fixed in after commit 1995266727fa.", {
        "entities": [
            [49, 57, "VERSION"],
            [60, 66, "VERSION"],
            [69, 75, "VERSION"],
            [78, 85, "VERSION"]
        ]
    }],
    ["Linux Linux kernel version at least v4.8 onwards, probably well before contains a Insufficient input validation vulnerability in bnx2x network card driver that can result in DoS: Network card firmware assertion takes card off-line. This attack appear to be exploitable via An attacker on a must pass a very large, specially crafted packet to the bnx2x card. This can be done from an untrusted guest VM..", {
        "entities": [
            [37, 40, "VERSION"],
            [135, 148, "DRIVER"]
        ]
    }],
    ["In the Linux kernel 4.12, 3.10, 2.6 and possibly earlier versions a race condition vulnerability exists in the sound system, this can lead to a deadlock and denial of service condition.", {
        "entities": [
            [20, 24, "VERSION"],
            [26, 30, "VERSION"],
            [32, 35, "VERSION"]
        ]
    }],
    ["arch/x86/kernel/paravirt.c in the Linux kernel before 4.18.1 mishandles certain indirect calls, which makes it easier for attackers to conduct Spectre-v2 attacks against paravirtual guests.", {
        "entities": [
            [54, 60, "VERSION"],
            [0, 26, "SOURCECODE"],
            [0, 23, "DRIVER"]
        ]
    }],
    ["drivers/infiniband/core/ucma.c in the Linux kernel through 4.17.11 allows ucma_leave_multicast to access a certain data structure after a cleanup step in ucma_process_join, which allows attackers to cause a denial of service (use-after-free).", {
        "entities": [
            [74, 94, "FUNCTION"],
            [154, 171, "FUNCTION"],
            [59, 66, "VERSION"],
            [0, 30, "SOURCECODE"],
            [0, 27, "DRIVER"]
        ]
    }],
    ["An issue was discovered in the Linux kernel through 4.17.11, as used in Xen through 4.11.x. The xen_failsafe_callback entry point in arch/x86/entry/entry_64.S does not properly maintain RBX, which allows local users to cause a denial of service (uninitialized memory usage and system crash). Within Xen, 64-bit x86 PV Linux guest OS users can trigger a guest OS crash or possibly gain privileges.", {
        "entities": [
            [96, 117, "FUNCTION"],
            [148, 156, "FUNCTION"],
            [52, 59, "VERSION"],
            [84, 88, "VERSION"],
            [133, 156, "DRIVER"]
        ]
    }],
    ["An issue was discovered in the Linux kernel through 4.17.10. There is a NULL pointer dereference and panic in hfsplus_lookup() in fs/hfsplus/dir.c when opening a file (that is purportedly a hard link) in an hfs+ filesystem that has malformed catalog data, and is mounted read-only without a metadata directory.", {
        "entities": [
            [110, 124, "FUNCTION"],
            [52, 59, "VERSION"],
            [130, 146, "SOURCECODE"],
            [130, 143, "DRIVER"]
        ]
    }],
    ["An issue was discovered in the Linux kernel through 4.17.10. There is a NULL pointer dereference in fscrypt_do_page_crypto() in fs/crypto/crypto.c when operating on a file in a corrupted f2fs image.", {
        "entities": [
            [100, 122, "FUNCTION"],
            [52, 59, "VERSION"],
            [128, 146, "SOURCECODE"],
            [128, 143, "DRIVER"]
        ]
    }]
]


def save_model(output_dir, model_name, nlp):
    if output_dir is not None:
        output_dir = Path(output_dir)
        if not output_dir.exists():
            output_dir.mkdir()
        nlp.meta['name'] = model_name  # rename model
        nlp.to_disk(output_dir)
        print("Saved model to", output_dir)


def get_model(model):
    if model is not None:
        nlp = spacy.load(model)  # load existing spaCy model
        print("Loaded model '%s'" % model)
    else:
        nlp = spacy.blank('en')  # create blank Language class
        print("Created blank 'en' model")
    return nlp


def get_ner_component(nlp):
    # Add entity recognizer to model if it's not in the pipeline
    # nlp.create_pipe works for built-ins that are registered with spaCy
    if 'ner' not in nlp.pipe_names:
        ner = nlp.create_pipe('ner')
        nlp.add_pipe(ner)
    # otherwise, get it, so we can add labels to it
    else:
        ner = nlp.get_pipe('ner')
    return ner


def get_optimizer(model, nlp):
    if model is None:
        optimizer = nlp.begin_training()
    else:
        # Note that 'begin_training' initializes the models, so it'll zero out
        # existing entity types.
        optimizer = nlp.entity.create_optimizer()
    return optimizer


def train(nlp, optimizer, n_iter, train_data):
    # get names of other pipes to disable them during training
    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']
    with nlp.disable_pipes(*other_pipes):  # only train NER
        for _ in range(n_iter):
            random.shuffle(train_data)
            losses = {}
            # batch up the examples using spaCy's minibatch
            batches = minibatch(train_data, size=compounding(4., 32., 1.001))
            for batch in batches:
                texts, annotations = zip(*batch)
                try:
                    nlp.update(unicode(texts), annotations, sgd=optimizer, drop=0.35,
                               losses=losses)
                except:
                    import ipdb
                    ipdb.set_trace()
            print('Losses', losses)


def test(nlp, test_data):
    doc = nlp(test_data)
    print("Entities in '%s'" % test_data)
    for ent in doc.ents:
        print(ent.label_, ent.text)


def main(model=None, new_model_name='animal', output_dir=None, n_iter=100):
    """Set up the pipeline and entity recognizer, and train the new entity."""
    train_data = TRAIN_DATA

    nlp = get_model(model)
    ner = get_ner_component(nlp)

    for label in LABELS:
        ner.add_label(label)   # add new entity label to entity recognizer

    optimizer = get_optimizer(model, nlp)

    train(nlp, optimizer, n_iter, train_data)

    # test the trained model
    test_data = "An issue was discovered in the Linux kernel through 4.17.10. There is an invalid pointer dereference in io_ctl_map_page() when mounting and operating a crafted btrfs image, because of a lack of block group item validation in check_leaf_item in fs/btrfs/tree-checker.c."
    test(nlp, test_data)


if __name__ == '__main__':
    main()
